from typing import List, Dict, Any
from langchain_experimental.text_splitter import SemanticChunker
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter

class TextChunker:
    """
    Lá»›p há»— trá»£ chunking vÄƒn báº£n vá»›i nhiá»u phÆ°Æ¡ng phÃ¡p khÃ¡c nhau.
    """

    def __init__(self, method: str = "semantic", **kwargs: Any) -> None:
        """
        Khá»Ÿi táº¡o bá»™ chia vÄƒn báº£n vá»›i phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c chá»n.

        Args:
            method (str): PhÆ°Æ¡ng phÃ¡p chunking, cÃ³ thá»ƒ lÃ :
                - "semantic": Chunk theo ngá»¯ nghÄ©a vá»›i OpenAI embeddings dÃ¹ng vá»›i dá»¯ liá»‡u phi cáº¥u trÃºc.
                - "character": Chunk theo kÃ½ tá»± cá»‘ Ä‘á»‹nh, phÃ¹ há»£p vá»›i dá»¯ liá»‡u cÃ³ cáº¥u trÃºc Ä‘Æ¡n giáº£n.
                - "recursive": Chunk theo recursive character splitting, cÃ³ thá»ƒ dÃ¹ng vá»›i dá»¯ liá»‡u bÃ¡n cáº¥u trÃºc.
            **kwargs (Any): CÃ¡c tham sá»‘ bá»• sung cho phÆ°Æ¡ng phÃ¡p chunking.
        """
        self.method: str = method
        self.kwargs: Dict[str, Any] = kwargs

        if method == "semantic":
            model: str = kwargs.get("model", "text-embedding-ada-002")
            buffer_size: int = kwargs.get("buffer_size", 1)
            breakpoint_threshold_amount: int = kwargs.get("breakpoint_threshold_amount", 70)
            embedding_model = OpenAIEmbeddings(model=model)
            self.chunker = SemanticChunker(
                buffer_size=buffer_size,
                breakpoint_threshold_amount=breakpoint_threshold_amount,
                embeddings=embedding_model
            )

        elif method == "character":
            chunk_size: int = kwargs.get("chunk_size", 1000)
            chunk_overlap: int = kwargs.get("chunk_overlap", 200)
            self.chunker = CharacterTextSplitter(
                chunk_size=chunk_size, 
                chunk_overlap=chunk_overlap
            )

        elif method == "recursive":
            chunk_size: int = kwargs.get("chunk_size", 1000)
            chunk_overlap: int = kwargs.get("chunk_overlap", 200)
            self.chunker = RecursiveCharacterTextSplitter(
                chunk_size=chunk_size, 
                chunk_overlap=chunk_overlap
            )

        else:
            raise ValueError(f"PhÆ°Æ¡ng phÃ¡p chunking '{method}' khÃ´ng Ä‘Æ°á»£c há»— trá»£!")

    def chunk(self, text: str) -> List[str]:
        """
        Chia vÄƒn báº£n thÃ nh cÃ¡c Ä‘oáº¡n theo phÆ°Æ¡ng phÃ¡p Ä‘Ã£ chá»n.

        Args:
            text (str): VÄƒn báº£n cáº§n chunk.

        Returns:
            List[str]: Danh sÃ¡ch cÃ¡c Ä‘oáº¡n vÄƒn báº£n sau khi chunk.
        """
        if self.method == "semantic":
            chunks = self.chunker.create_documents([text])
            return [chunk.page_content for chunk in chunks]
        else:
            return self.chunker.split_text(text)


# # =========================
# # ğŸ“Œ VÃ­ dá»¥ sá»­ dá»¥ng
# # =========================

# docs = """HÃ´m nay lÃ  má»™t ngÃ y tuyá»‡t vá»i Ä‘á»ƒ báº¯t Ä‘áº§u báº±ng má»™t tÃ¡ch cÃ  phÃª nÃ³ng há»•i. 
# Sau khi thÆ°á»Ÿng thá»©c bá»¯a sÃ¡ng, tÃ´i quyáº¿t Ä‘á»‹nh Ä‘i dáº¡o trong cÃ´ng viÃªn gáº§n
# nhÃ , nÆ¡i cÃ¢y cá»‘i xanh tÆ°Æ¡i vÃ  tiáº¿ng chim hÃ³t rá»™n rÃ ng. Tuy nhiÃªn, tÃ´i hÆ¡i
# tháº¥t vá»ng vÃ¬ cÃ´ng viÃªn khÃ¡ Ä‘Ã´ng Ä‘Ãºc, khiáº¿n khÃ´ng khÃ­ yÃªn bÃ¬nh thÆ°á»ng ngÃ y
# bá»‹ phÃ¡ vá»¡. Máº·c dÃ¹ váº­y, tÃ´i váº«n tÃ¬m Ä‘Æ°á»£c má»™t gÃ³c nhá» yÃªn tÄ©nh Ä‘á»ƒ Ä‘á»c cuá»‘n
# sÃ¡ch yÃªu thÃ­ch. Sau buá»•i sÃ¡ng trong lÃ nh, tÃ´i quay vá» nhÃ  Ä‘á»ƒ lÃ m viá»‡c. 
# CÃ´ng viá»‡c hÃ´m nay khÃ¡ báº­n rá»™n, nhÆ°ng tÃ´i cáº£m tháº¥y ráº¥t hÃ i lÃ²ng vÃ¬ hoÃ n 
# thÃ nh Ä‘Æ°á»£c má»™t dá»± Ã¡n lá»›n. Buá»•i tá»‘i, tÃ´i tá»± thÆ°á»Ÿng cho mÃ¬nh má»™t bá»¯a Äƒn ngon
# vÃ  xem má»™t bá»™ phim hÃ i trÆ°á»›c khi Ä‘i ngá»§."""

# # Chunking theo ngá»¯ nghÄ©a
# semantic_chunker = TextChunker(method="semantic")
# chunks_semantic = semantic_chunker.chunk(docs)
# print("ğŸ“Œ Chunking theo ngá»¯ nghÄ©a:")
# for i, chunk in enumerate(chunks_semantic):
#     print(f"Chunk {i+1}:\n{chunk}\n")

# # Chunking theo kÃ½ tá»± (fixed-size character splitting)
# char_chunker = TextChunker(method="character", chunk_size=150, chunk_overlap=30)
# chunks_character = char_chunker.chunk(docs)
# print("ğŸ“Œ Chunking theo kÃ½ tá»±:")
# for i, chunk in enumerate(chunks_character):
#     print(f"Chunk {i+1}:\n{chunk}\n")

# # Chunking theo recursive character splitting
# recursive_chunker = TextChunker(method="recursive", chunk_size=150, chunk_overlap=30)
# chunks_recursive = recursive_chunker.chunk(docs)
# print("ğŸ“Œ Chunking theo recursive character splitting:")
# for i, chunk in enumerate(chunks_recursive):
#     print(f"Chunk {i+1}:\n{chunk}\n")
