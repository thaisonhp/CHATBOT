from rank_bm25 import BM25Okapi
import numpy as np
from langchain_openai import OpenAIEmbeddings
import os 
import chromadb

# Kh·ªüi t·∫°o client v√† collection
chroma_client = chromadb.PersistentClient(path="./chroma_db")  # ƒê∆∞·ªùng d·∫´n database
collection = chroma_client.get_or_create_collection(name="langchain")

def get_documents():
    """L·∫•y danh s√°ch t√†i li·ªáu t·ª´ ChromaDB"""
    results = collection.get(include=["documents", "metadatas"])  # L·∫•y c·∫£ metadata n·∫øu c·∫ßn
    return results["documents"], results["metadatas"]

# L·∫•y danh s√°ch t√†i li·ªáu t·ª´ database
documents, metadatas = get_documents()
tokenized_corpus = [doc.split(" ") for doc in documents]
bm25 = BM25Okapi(tokenized_corpus)

def hybrid_search(query, embedding_model=None, top_k=5, alpha=0.5):
    """K·∫øt h·ª£p BM25 v√† Vector Search ƒë·ªÉ c·∫£i thi·ªán k·∫øt qu·∫£ truy xu·∫•t"""
    if embedding_model is None:
        embedding_model = OpenAIEmbeddings()  # S·ª≠ d·ª•ng OpenAIEmbeddings m·∫∑c ƒë·ªãnh

    # 1Ô∏è‚É£ BM25 Search
    tokenized_query = query.split(" ")
    bm25_scores = bm25.get_scores(tokenized_query)

    # 2Ô∏è‚É£ Vector Search t·ª´ ChromaDB
    query_embedding = embedding_model.embed_query(query)
    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)

    # L·∫•y danh s√°ch ID t·ª´ ChromaDB
    retrieved_ids = results.get("ids", [[]])[0]  # Tr√°nh l·ªói n·∫øu kh√¥ng c√≥ k·∫øt qu·∫£
    retrieved_distances = results.get("distances", [[]])[0]  

    # 3Ô∏è‚É£ K·∫øt h·ª£p ƒëi·ªÉm BM25 + Vector Search
    bm25_scores = np.array(bm25_scores)
    bm25_ranks = np.argsort(-bm25_scores)[:top_k]

    hybrid_results = {}
    all_doc_ids = collection.get()["ids"]  # L·∫•y danh s√°ch ID t·ª´ ChromaDB

    for idx, doc_id in enumerate(retrieved_ids):
        if doc_id in all_doc_ids:
            doc_index = all_doc_ids.index(doc_id)  # L·∫•y index c·ªßa doc_id
            hybrid_score = alpha * bm25_scores[doc_index] + (1 - alpha) * retrieved_distances[idx]
            hybrid_results[doc_id] = hybrid_score
        else:
            print(f"‚ö†Ô∏è Warning: doc_id {doc_id} kh√¥ng t√¨m th·∫•y trong collection.")

    sorted_results = sorted(hybrid_results.items(), key=lambda x: x[1], reverse=True)
    
    return [documents[all_doc_ids.index(idx)] for idx, _ in sorted_results if idx in all_doc_ids]

# Test t√¨m ki·∫øm v·ªõi Hybrid Search
embedding_model = OpenAIEmbeddings()
query = "L∆∞∆°ng Th√°i S∆°n l√† ai?"
retrieved_docs = hybrid_search(query, embedding_model)
print("üîç K·∫øt qu·∫£ truy xu·∫•t:", retrieved_docs)
